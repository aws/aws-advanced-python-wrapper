#  Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.
#
#  Licensed under the Apache License, Version 2.0 (the "License").
#  You may not use this file except in compliance with the License.
#  You may obtain a copy of the License at
#
#  http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an "AS IS" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.

# flake8: noqa: N806
# N806: Django model class references stored in variables use PascalCase intentionally

from __future__ import annotations

import json
import uuid
from time import perf_counter_ns, sleep
from typing import Any, ClassVar, Dict

import boto3
import django
import pytest
from boto3 import client
from botocore.exceptions import ClientError
from django.conf import settings
from django.db import connection, connections, models
from django.test.utils import setup_test_environment, teardown_test_environment

from aws_advanced_python_wrapper.errors import FailoverSuccessError
from tests.integration.container.utils.rds_test_utility import RdsTestUtility
from ..utils.conditions import (disable_on_features, enable_on_deployments,
                                enable_on_engines, enable_on_features,
                                enable_on_num_instances)
from ..utils.database_engine import DatabaseEngine
from ..utils.database_engine_deployment import DatabaseEngineDeployment
from ..utils.test_environment import TestEnvironment
from ..utils.test_environment_features import TestEnvironmentFeatures


@enable_on_engines([DatabaseEngine.MYSQL])  # Django backends are MySQL-specific
@enable_on_deployments([DatabaseEngineDeployment.AURORA, DatabaseEngineDeployment.RDS_MULTI_AZ_CLUSTER])
@disable_on_features([TestEnvironmentFeatures.RUN_AUTOSCALING_TESTS_ONLY,
                      TestEnvironmentFeatures.BLUE_GREEN_DEPLOYMENT,
                      TestEnvironmentFeatures.PERFORMANCE])
class TestDjangoPlugins:
    # Type hints for dynamically created Django models (using Any to avoid mypy errors)
    TestModel: Any

    # Class variables for custom endpoint
    endpoint_id: ClassVar[str] = f"test-django-endpoint-{uuid.uuid4()}"
    endpoint_info: ClassVar[Dict[str, Any]] = {}
    reuse_existing_endpoint: ClassVar[bool] = False

    @pytest.fixture(scope='class')
    def rds_utils(self):
        region: str = TestEnvironment.get_current().get_info().get_region()
        return RdsTestUtility(region)

    @pytest.fixture(scope='class')
    def create_secret(self, conn_utils):
        """Create a secret in AWS Secrets Manager with database credentials."""
        region = TestEnvironment.get_current().get_info().get_region()
        client = boto3.client('secretsmanager', region_name=region)
        env = TestEnvironment.get_current()

        secret_name = f"TestSecret-{uuid.uuid4()}"

        engine = "postgres" if env.get_engine() == "pg" else "mysql"
        secret_value = {
            "engine": engine,
            "dbname": env.get_info().get_database_info().get_default_db_name(),
            "host": env.get_info().get_database_info().get_cluster_endpoint(),
            "username": conn_utils.user,
            "password": conn_utils.password,
            "description": "Test secret generated by integration tests."
        }

        try:
            response = client.create_secret(
                Name=secret_name,
                SecretString=json.dumps(secret_value)
            )
            secret_arn = response['ARN']
            yield secret_name, secret_arn
        finally:
            try:
                client.delete_secret(
                    SecretId=secret_name,
                    ForceDeleteWithoutRecovery=True
                )
            except Exception:
                pass

    @pytest.fixture(scope='class')
    def create_custom_endpoint(self):
        """Create a custom endpoint for testing"""
        env_info = TestEnvironment.get_current().get_info()
        region = env_info.get_region()

        rds_client = client('rds', region_name=region)
        if not self.reuse_existing_endpoint:
            instances = env_info.get_database_info().get_instances()
            self._create_endpoint(rds_client, instances[0:1])

        self._wait_until_endpoint_available(rds_client)

        yield

        if not self.reuse_existing_endpoint:
            self._delete_endpoint(rds_client)

        rds_client.close()

    def _wait_until_endpoint_available(self, rds_client):
        """Wait until the custom endpoint becomes available"""
        end_ns = perf_counter_ns() + 5 * 60 * 1_000_000_000  # 5 minutes
        available = False

        while perf_counter_ns() < end_ns:
            response = rds_client.describe_db_cluster_endpoints(
                DBClusterEndpointIdentifier=self.endpoint_id,
                Filters=[
                    {
                        "Name": "db-cluster-endpoint-type",
                        "Values": ["custom"]
                    }
                ]
            )

            response_endpoints = response["DBClusterEndpoints"]
            if len(response_endpoints) != 1:
                sleep(3)  # Endpoint needs more time to get created.
                continue

            response_endpoint = response_endpoints[0]
            TestDjangoPlugins.endpoint_info = response_endpoint
            available = "available" == response_endpoint["Status"]
            if available:
                break

            sleep(3)

        if not available:
            pytest.fail(f"The test setup step timed out while waiting for the test custom endpoint to become available: "
                        f"'{TestDjangoPlugins.endpoint_id}'.")

    def _create_endpoint(self, rds_client, instances):
        """Create the custom endpoint"""
        instance_ids = [instance.get_instance_id() for instance in instances]
        rds_client.create_db_cluster_endpoint(
            DBClusterEndpointIdentifier=self.endpoint_id,
            DBClusterIdentifier=TestEnvironment.get_current().get_cluster_name(),
            EndpointType="ANY",
            StaticMembers=instance_ids
        )

    def _delete_endpoint(self, rds_client):
        """Delete the custom endpoint and wait for deletion"""
        try:
            rds_client.delete_db_cluster_endpoint(DBClusterEndpointIdentifier=self.endpoint_id)
            # Wait for the endpoint to be deleted
            self._wait_until_endpoint_deleted(rds_client)
        except ClientError as e:
            # If the custom endpoint already does not exist, we can continue. Otherwise, fail the test.
            if e.response['Error']['Code'] != 'DBClusterEndpointNotFoundFault':
                pytest.fail(e)

    def _wait_until_endpoint_deleted(self, rds_client):
        """Wait until the custom endpoint is deleted (max 3 minutes)"""
        end_ns = perf_counter_ns() + 3 * 60 * 1_000_000_000  # 3 minutes
        deleted = False

        while perf_counter_ns() < end_ns:
            try:
                response = rds_client.describe_db_cluster_endpoints(
                    DBClusterEndpointIdentifier=self.endpoint_id,
                    Filters=[
                        {
                            "Name": "db-cluster-endpoint-type",
                            "Values": ["custom"]
                        }
                    ]
                )

                response_endpoints = response["DBClusterEndpoints"]
                if len(response_endpoints) == 0:
                    deleted = True
                    break

                # Check if endpoint is in deleting state
                endpoint_status = response_endpoints[0]["Status"]
                if endpoint_status == "deleting":
                    sleep(3)
                    continue

            except ClientError as e:
                # If we get DBClusterEndpointNotFoundFault, the endpoint is deleted
                if e.response['Error']['Code'] == 'DBClusterEndpointNotFoundFault':
                    deleted = True
                    break
                else:
                    # Some other error occurred
                    sleep(3)
                    continue

            sleep(3)

        if not deleted:
            print(f"Warning: Timed out waiting for custom endpoint to be deleted: '{self.endpoint_id}'. "
                  f"The endpoint may still be in the process of being deleted.")
        else:
            print(f"Custom endpoint '{self.endpoint_id}' successfully deleted.")

    @pytest.fixture(scope='function')  # Changed from 'class' to 'function'
    def django_models(self, django_setup):
        """Create Django models after Django is set up"""

        # Use unique app labels and table names for each test to avoid conflicts
        test_id = str(uuid.uuid4())[:8]  # Short unique identifier

        # Store models in class attributes so they're accessible
        class TestModel(models.Model):
            """Basic test model for Django ORM functionality"""
            name = models.CharField(max_length=100)
            email = models.EmailField()
            age = models.IntegerField()
            is_active = models.BooleanField(default=True)
            created_at = models.DateTimeField(auto_now_add=True)

            class Meta:
                app_label = f'test_app_{test_id}'  # Unique app label
                db_table = f'django_test_model_plugins_{test_id}'

        class DataTypeModel(models.Model):
            """Model for testing various data types"""
            # String fields
            char_field = models.CharField(max_length=255, null=True, blank=True)
            text_field = models.TextField(null=True, blank=True)

            # Numeric fields
            integer_field = models.IntegerField(null=True, blank=True)
            big_integer_field = models.BigIntegerField(null=True, blank=True)
            decimal_field = models.DecimalField(max_digits=10, decimal_places=2, null=True, blank=True)
            float_field = models.FloatField(null=True, blank=True)

            # Boolean field
            boolean_field = models.BooleanField(default=False)

            # Date/Time fields
            date_field = models.DateField(null=True, blank=True)
            time_field = models.TimeField(null=True, blank=True)
            datetime_field = models.DateTimeField(null=True, blank=True)

            # JSON field (MySQL 5.7+)
            json_field = models.JSONField(null=True, blank=True)

            class Meta:
                app_label = f'test_app_{test_id}'  # Unique app label
                db_table = f'django_data_type_model_plugins_{test_id}'

        class Author(models.Model):
            """Author model for relationship testing"""
            name = models.CharField(max_length=100)
            email = models.EmailField()
            birth_date = models.DateField(null=True, blank=True)

            class Meta:
                app_label = f'test_app_{test_id}'  # Unique app label
                db_table = f'django_author_plugins_{test_id}'

        class Book(models.Model):
            """Book model for relationship testing"""
            title = models.CharField(max_length=200)
            author = models.ForeignKey(Author, on_delete=models.CASCADE, related_name='books')
            publication_date = models.DateField()
            pages = models.IntegerField()
            price = models.DecimalField(max_digits=8, decimal_places=2)

            class Meta:
                app_label = f'test_app_{test_id}'  # Unique app label
                db_table = f'django_book_plugins_{test_id}'

        # Store models as class attributes for easy access
        TestDjangoPlugins.TestModel = TestModel
        TestDjangoPlugins.DataTypeModel = DataTypeModel
        TestDjangoPlugins.Author = Author
        TestDjangoPlugins.Book = Book

        # Create tables for our test models
        with connection.schema_editor() as schema_editor:
            schema_editor.create_model(TestModel)
            schema_editor.create_model(DataTypeModel)
            schema_editor.create_model(Author)
            schema_editor.create_model(Book)

        yield

        # Clean up tables - this will drop and recreate for each test
        with connection.schema_editor() as schema_editor:
            schema_editor.delete_model(Book)
            schema_editor.delete_model(Author)
            schema_editor.delete_model(DataTypeModel)
            schema_editor.delete_model(TestModel)

    @pytest.fixture(scope='function')  # Changed from 'class' to 'function'
    def django_setup(self, conn_utils, create_secret, request, create_custom_endpoint=None):
        """Setup Django configuration for testing with configurable plugins"""
        # Get configuration from test parameter or use defaults
        if hasattr(request, 'param') and isinstance(request.param, dict):
            config = request.param
            plugins_config = config.get('plugins', 'aurora_connection_tracker,failover2')
            extra_options = config.get('options', {})

            # Check if we need to use custom endpoint
            use_custom_endpoint = config.get('use_custom_endpoint', False)
            custom_endpoint_host = None

            if use_custom_endpoint and create_custom_endpoint:
                # create_custom_endpoint is a fixture that sets up the endpoint
                # The endpoint info is stored in the class variable
                custom_endpoint_host = self.endpoint_info.get('Endpoint')

            # Determine user based on plugin type
            if 'iam' in plugins_config:
                user = conn_utils.iam_user
            elif 'aws_secrets_manager' in plugins_config:
                user = None  # Secrets manager will provide credentials
                _, secret_arn = create_secret
                extra_options['secrets_manager_secret_id'] = secret_arn
            else:
                user = config.get('user', conn_utils.user)

            # Handle password
            if 'iam' in plugins_config or 'aws_secrets_manager' in plugins_config:
                password = None  # Secrets manager will provide credentials
            else:
                password = config.get('password', conn_utils.password)

            # Use custom endpoint host if provided, otherwise use default
            if custom_endpoint_host:
                host = custom_endpoint_host
            else:
                host = config.get('host', conn_utils.writer_cluster_host)
        else:
            plugins_config = 'aurora_connection_tracker,failover2'
            extra_options = {}
            user = conn_utils.user
            password = conn_utils.password
            host = conn_utils.writer_host

        # Configure Django settings
        if not settings.configured:
            db_config = {
                'ENGINE': 'aws_advanced_python_wrapper.django.backends.mysql_connector',
                'NAME': conn_utils.dbname,
                "USER": user,
                "PASSWORD": password,
                'HOST': host,
                'PORT': conn_utils.port,
                'OPTIONS': {
                    'plugins': plugins_config,  # Configurable plugins
                    'connect_timeout': 10,
                    'autocommit': True,
                    **extra_options  # Add any extra options
                },
            }

            settings.configure(
                DEBUG=True,
                DATABASES={'default': db_config},
                INSTALLED_APPS=[
                    'django.contrib.contenttypes',
                    'django.contrib.auth',
                ],
                SECRET_KEY='test-secret-key-for-django-plugins-tests',
                USE_TZ=True,
            )
        else:
            # If settings are already configured, update the database config
            settings.DATABASES['default']['USER'] = user
            settings.DATABASES['default']['PASSWORD'] = password
            settings.DATABASES['default']['HOST'] = host
            settings.DATABASES['default']['OPTIONS']['plugins'] = plugins_config
            settings.DATABASES['default']['OPTIONS'].update(extra_options)

        django.setup()
        setup_test_environment()

        yield {'plugins': plugins_config, 'options': extra_options}  # Return the config so tests can access it

        # Close all Django database connections after each test
        connections.close_all()
        teardown_test_environment()

    def test_django_basic_insert_with_plugins(self, test_environment: TestEnvironment, django_models):
        """Test basic Django insert operation with plugins enabled"""
        TestModel = self.TestModel

        # Ensure clean slate
        TestModel.objects.all().delete()

        # Create a simple test record
        test_obj = TestModel.objects.create(
            name="Plugin Test User",
            email="plugin@example.com",
            age=25,
            is_active=True
        )

        # Verify the record was created successfully
        assert test_obj.id is not None
        assert test_obj.name == "Plugin Test User"
        assert test_obj.email == "plugin@example.com"
        assert test_obj.age == 25
        assert test_obj.is_active is True

        # Verify we can retrieve it
        retrieved_obj = TestModel.objects.get(id=test_obj.id)
        assert retrieved_obj.name == "Plugin Test User"

        # Clean up
        TestModel.objects.all().delete()

    @pytest.mark.parametrize('django_setup', [{'plugins': ''}], indirect=True)
    def test_django_with_no_plugins(self, test_environment: TestEnvironment, django_models, django_setup):
        """Test Django with no plugins enabled"""
        TestModel = self.TestModel
        config = django_setup  # Get the config from fixture

        # Verify no plugins are configured
        assert config['plugins'] == ''

        # Test basic functionality still works
        test_obj = TestModel.objects.create(
            name="No Plugins User",
            email="noplugins@example.com",
            age=30
        )

        assert test_obj.id is not None
        assert test_obj.name == "No Plugins User"

        # Clean up
        TestModel.objects.all().delete()

    @pytest.mark.parametrize('django_setup', [{'plugins': 'failover'}], indirect=True)
    def test_django_with_failover_only(self, test_environment: TestEnvironment, django_models, django_setup):
        """Test Django with only failover plugin"""
        TestModel = self.TestModel
        config = django_setup  # Get the config from fixture

        # Verify only failover plugin is configured
        assert config['plugins'] == 'failover'

        # Test basic functionality works with failover plugin
        test_obj = TestModel.objects.create(
            name="Failover Only User",
            email="failover@example.com",
            age=35
        )

        assert test_obj.id is not None
        assert test_obj.name == "Failover Only User"

        # Clean up
        TestModel.objects.all().delete()

    @pytest.mark.parametrize('django_setup', [{'plugins': 'aurora_connection_tracker,failover2'}], indirect=True)
    def test_django_with_multiple_plugins(self, test_environment: TestEnvironment, django_models, django_setup):
        """Test Django with multiple plugins enabled"""
        TestModel = self.TestModel
        config = django_setup  # Get the config from fixture

        # Verify multiple plugins are configured
        assert config['plugins'] == 'aurora_connection_tracker,failover2'

        # Test basic functionality works with multiple plugins
        test_obj = TestModel.objects.create(
            name="Multi Plugin User",
            email="multiplugin@example.com",
            age=40
        )

        assert test_obj.id is not None
        assert test_obj.name == "Multi Plugin User"

        # Clean up
        TestModel.objects.all().delete()

    @pytest.mark.parametrize('django_setup', [{
        'plugins': 'aws_secrets_manager',
        'use_secrets_manager': True
    }], indirect=True)
    def test_django_with_secrets_manager_plugin(self, test_environment: TestEnvironment, django_setup, django_models):
        """Test Django with AWS Secrets Manager plugin"""
        TestModel = self.TestModel
        config = django_setup

        # Verify secrets manager plugin is configured
        assert config['plugins'] == 'aws_secrets_manager'
        assert 'secrets_manager_secret_id' in config['options']

        # Test basic functionality works with secrets manager
        test_obj = TestModel.objects.create(
            name="Secrets Manager User",
            email="secrets@example.com",
            age=45
        )

        assert test_obj.id is not None
        assert test_obj.name == "Secrets Manager User"

        # Verify we can retrieve the record
        retrieved_obj = TestModel.objects.get(id=test_obj.id)
        assert retrieved_obj.email == "secrets@example.com"

        # Clean up
        TestModel.objects.all().delete()

    @pytest.mark.parametrize('django_setup', [{
        'plugins': 'iam',
        'password': '<anything>',  # IAM doesn't use password
        'options': {}
    }], indirect=True)
    def test_django_with_iam_plugin(self, test_environment: TestEnvironment, django_models, django_setup, conn_utils):
        """Test Django with IAM authentication plugin"""
        TestModel = self.TestModel
        config = django_setup

        # Verify IAM plugin is configured
        assert config['plugins'] == 'iam'

        # Add iam_host to the configuration
        if settings.configured:
            # Get the writer instance for IAM host
            writer_instance = test_environment.get_writer()
            settings.DATABASES['default']['OPTIONS']['iam_host'] = writer_instance.get_host()

        # Test basic functionality works with IAM authentication
        test_obj = TestModel.objects.create(
            name="IAM User",
            email="iam@example.com",
            age=50
        )

        assert test_obj.id is not None
        assert test_obj.name == "IAM User"

        # Verify we can retrieve the record
        retrieved_obj = TestModel.objects.get(id=test_obj.id)
        assert retrieved_obj.email == "iam@example.com"

        # Clean up
        TestModel.objects.all().delete()

    @pytest.mark.parametrize('django_setup', [{
        'plugins': 'failover',
        'options': {
            'socket_timeout': 10,
            'connect_timeout': 10,
            'monitoring-connect_timeout': 5,
            'monitoring-socket_timeout': 5,
            'topology_refresh_ms': 10
        }
    }], indirect=True)
    @enable_on_features([TestEnvironmentFeatures.FAILOVER_SUPPORTED])
    @enable_on_num_instances(min_instances=2)
    def test_django_failover_during_query(self, test_environment: TestEnvironment, django_setup, django_models, rds_utils):
        """Test Django failover during query operations"""
        TestModel = self.TestModel
        config = django_setup

        # Verify failover plugin is configured
        assert 'failover' in config['plugins']

        # Get initial writer ID
        initial_writer_id = rds_utils.get_cluster_writer_instance_id()

        # Create a test record
        test_obj = TestModel.objects.create(
            name="Failover Test User",
            email="failover@example.com",
            age=30
        )

        # Select something from the TestModel - should work fine
        result = TestModel.objects.filter(id=test_obj.id).first()
        assert result is not None
        assert result.name == "Failover Test User"

        # Trigger failover
        rds_utils.failover_cluster_and_wait_until_writer_changed()

        # Try selecting again - should throw FailoverSuccessError
        with pytest.raises(FailoverSuccessError):
            TestModel.objects.filter(id=test_obj.id).first()

        # Select again - should work fine now (connected to new writer)
        result = TestModel.objects.filter(id=test_obj.id).first()
        assert result is not None
        assert result.name == "Failover Test User"

        # Verify we're now connected to a new writer
        with connection.cursor() as cursor:
            cursor.execute(RdsTestUtility.get_instance_id_query())
            current_writer_id = cursor.fetchone()[0]
            assert rds_utils.is_db_instance_writer(current_writer_id) is True
            assert current_writer_id != initial_writer_id, "Should be connected to a new writer after failover"

        # Clean up test data
        TestModel.objects.all().delete()

    @pytest.mark.parametrize('django_setup', [{
        'plugins': 'custom_endpoint,failover2',
        'use_custom_endpoint': True,
        'options': {
            'socket_timeout': 10,
            'connect_timeout': 10,
            'monitoring-connect_timeout': 5,
            'monitoring-socket_timeout': 5,
            'topology_refresh_ms': 10
        }
    }], indirect=True)
    @enable_on_features([TestEnvironmentFeatures.FAILOVER_SUPPORTED])
    @enable_on_num_instances(min_instances=2)
    def test_django_custom_endpoint_failover_during_query(
            self, test_environment: TestEnvironment, create_custom_endpoint,
            django_setup, django_models, rds_utils):
        """Test Django failover with custom endpoint during query operations"""
        TestModel = self.TestModel
        config = django_setup

        # Verify custom_endpoint and failover plugins are configured
        assert 'custom_endpoint' in config['plugins']
        assert 'failover' in config['plugins']

        # Get initial writer ID
        initial_writer_id = rds_utils.get_cluster_writer_instance_id()

        # Create a test record
        test_obj = TestModel.objects.create(
            name="Custom Endpoint Failover Test User",
            email="custom_failover@example.com",
            age=35
        )

        # Step 1: Select something from the TestModel - should work fine
        result = TestModel.objects.filter(id=test_obj.id).first()
        assert result is not None
        assert result.name == "Custom Endpoint Failover Test User"

        # Trigger failover
        rds_utils.failover_cluster_and_wait_until_writer_changed()

        # Try selecting again - should throw FailoverSuccessError
        with pytest.raises(FailoverSuccessError):
            TestModel.objects.filter(id=test_obj.id).first()

        # Select again - should work fine now (connected to new writer)
        result = TestModel.objects.filter(id=test_obj.id).first()
        assert result is not None
        assert result.name == "Custom Endpoint Failover Test User"

        # Verify we're now connected to a new writer
        with connection.cursor() as cursor:
            cursor.execute(RdsTestUtility.get_instance_id_query())
            current_writer_id = cursor.fetchone()[0]
            assert rds_utils.is_db_instance_writer(current_writer_id) is True
            assert current_writer_id != initial_writer_id, "Should be connected to a new writer after failover"

        # Clean up test data
        TestModel.objects.all().delete()

    @pytest.fixture(scope='function')
    def django_rw_split_setup(self, conn_utils):
        """Setup Django with read/write splitting configuration"""
        # Define a router class for read/write splitting
        class ReadWriteRouter:
            """Router to direct reads to 'read' database and writes to 'default' database"""

            def db_for_read(self, model, **hints):
                """Direct all read operations to the 'read' database"""
                return 'read'

            def db_for_write(self, model, **hints):
                """Direct all write operations to the 'default' database"""
                return 'default'

            def allow_relation(self, obj1, obj2, **hints):
                """Allow relations between objects in the same database"""
                return True

            def allow_migrate(self, db, app_label, model_name=None, **hints):
                """Allow migrations on all databases"""
                return True

        # Configure Django with two database connections
        if not settings.configured:
            db_config_writer = {
                'ENGINE': 'aws_advanced_python_wrapper.django.backends.mysql_connector',
                'NAME': conn_utils.dbname,
                'USER': conn_utils.user,
                'PASSWORD': conn_utils.password,
                'HOST': conn_utils.writer_cluster_host,
                'PORT': conn_utils.port,
                'OPTIONS': {
                    'plugins': 'read_write_splitting',
                    'connect_timeout': 10,
                    'autocommit': True,
                },
            }

            db_config_reader = {
                'ENGINE': 'aws_advanced_python_wrapper.django.backends.mysql_connector',
                'NAME': conn_utils.dbname,
                'USER': conn_utils.user,
                'PASSWORD': conn_utils.password,
                'HOST': conn_utils.writer_cluster_host,
                'PORT': conn_utils.port,
                'OPTIONS': {
                    'plugins': 'read_write_splitting',
                    'connect_timeout': 10,
                    'autocommit': True,
                    'read_only': True,
                },
            }

            settings.configure(
                DEBUG=True,
                DATABASES={
                    'default': db_config_writer,  # Writer connection
                    'read': db_config_reader,      # Reader connection
                },
                DATABASE_ROUTERS=[ReadWriteRouter()],
                INSTALLED_APPS=[
                    'django.contrib.contenttypes',
                    'django.contrib.auth',
                ],
                SECRET_KEY='test-secret-key-for-rw-splitting',
                USE_TZ=True,
            )
        else:
            # Update existing settings without overwriting
            settings.DATABASES['default'].update({
                'ENGINE': 'aws_advanced_python_wrapper.django.backends.mysql_connector',
                'NAME': conn_utils.dbname,
                'USER': conn_utils.user,
                'PASSWORD': conn_utils.password,
                'HOST': conn_utils.writer_cluster_host,
                'PORT': conn_utils.port,
            })
            settings.DATABASES['default']['OPTIONS'].update({
                'plugins': 'read_write_splitting',
                'connect_timeout': 10,
                'autocommit': True,
            })

            # Create or update the 'read' database configuration
            if 'read' not in settings.DATABASES:
                settings.DATABASES['read'] = settings.DATABASES['default'].copy()
                settings.DATABASES['read']['OPTIONS'] = settings.DATABASES['default']['OPTIONS'].copy()
                settings.DATABASES['read'].update({
                    'OPTIONS': {
                        'plugins': 'read_write_splitting',
                        'connect_timeout': 10,
                        'autocommit': True,
                        'read_only': True,
                    },
                })
            else:
                settings.DATABASES['read'].update({
                    'ENGINE': 'aws_advanced_python_wrapper.django.backends.mysql_connector',
                    'NAME': conn_utils.dbname,
                    'USER': conn_utils.user,
                    'PASSWORD': conn_utils.password,
                    'HOST': conn_utils.writer_cluster_host,
                    'PORT': conn_utils.port,
                })
                settings.DATABASES['read']['OPTIONS'].update({
                    'plugins': 'read_write_splitting',
                    'connect_timeout': 10,
                    'autocommit': True,
                    'read_only': True,
                })

            settings.DATABASE_ROUTERS = [ReadWriteRouter()]

        django.setup()
        setup_test_environment()

        # Create a test model
        test_id = str(uuid.uuid4())[:8]

        class RWSplitTestModel(models.Model):
            name = models.CharField(max_length=100)
            value = models.IntegerField()

            class Meta:
                app_label = f'test_app_{test_id}'
                db_table = f'django_rw_split_test_{test_id}'

        # Create table once on the default (writer) connection
        # Both connections point to the same database, so only create schema once
        with connections['default'].schema_editor() as schema_editor:
            schema_editor.create_model(RWSplitTestModel)

        yield RWSplitTestModel

        # Cleanup: Drop table and close connections
        with connections['default'].schema_editor() as schema_editor:
            schema_editor.delete_model(RWSplitTestModel)

        connections.close_all()
        teardown_test_environment()

    @enable_on_num_instances(min_instances=2)
    def test_django_read_write_splitting(self, test_environment: TestEnvironment, django_rw_split_setup, rds_utils):
        """Test Django with read/write splitting using multiple database connections"""
        RWSplitTestModel = django_rw_split_setup

        # Verify writer connection is connected to writer endpoint
        with connections['default'].cursor() as cursor:
            cursor.execute(RdsTestUtility.get_instance_id_query())
            writer_instance_id = cursor.fetchone()[0]
            assert rds_utils.is_db_instance_writer(writer_instance_id), \
                f"Default connection should be connected to writer, but got {writer_instance_id}"

        # Verify reader connection is connected to reader endpoint
        with connections['read'].cursor() as cursor:
            cursor.execute(RdsTestUtility.get_instance_id_query())
            reader_instance_id = cursor.fetchone()[0]
            assert not rds_utils.is_db_instance_writer(reader_instance_id), \
                f"Read connection should be connected to reader, but got {reader_instance_id}"

        # Verify they're different instances
        assert writer_instance_id != reader_instance_id, \
            "Writer and reader should be connected to different instances"

        # Perform write operation (should use 'default' database)
        test_obj = RWSplitTestModel.objects.using('default').create(
            name="Test Write",
            value=42
        )
        assert test_obj.id is not None

        # Perform read operation (should use 'read' database via router)
        # Note: The router directs reads to 'read' database
        retrieved_obj = RWSplitTestModel.objects.get(id=test_obj.id)
        assert retrieved_obj.name == "Test Write"
        assert retrieved_obj.value == 42

        # Verify we can do more complex operations
        # Create multiple objects
        RWSplitTestModel.objects.using('default').create(name="Object 1", value=10)
        RWSplitTestModel.objects.using('default').create(name="Object 2", value=20)
        RWSplitTestModel.objects.using('default').create(name="Object 3", value=30)

        # Read them back (router will use 'read' database)
        all_objects = RWSplitTestModel.objects.all()
        assert all_objects.count() == 4  # Including the first test_obj

        # Filter operation (read) - should find objects with value >= 20
        # This includes: test_obj (42), Object 2 (20), Object 3 (30) = 3 objects
        filtered = RWSplitTestModel.objects.filter(value__gte=20)
        assert filtered.count() == 3

        # Update operation (write - should use 'default')
        RWSplitTestModel.objects.filter(name="Object 1").update(value=15)

        # Verify update (read)
        updated_obj = RWSplitTestModel.objects.get(name="Object 1")
        assert updated_obj.value == 15

        # Clean up test data
        RWSplitTestModel.objects.using('default').all().delete()
